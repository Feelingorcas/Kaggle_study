{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+3MdarYretEc46umS7VYh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Feelingorcas/Kaggle_study/blob/master/Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L_O7fIlAfZK"
      },
      "outputs": [],
      "source": [
        "## code for kaggle  https://www.kaggle.com/competitions/titanic/data\n",
        "## first introduction for kaggle \n",
        "\n",
        "\n",
        "\n",
        "## 데이터 받고, 전 처리 하고, 모델학습 시키고, 결과 얻기.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## librarys should include hear to get up\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive/\") \n",
        "import torch \n",
        "import torch.nn \n",
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEr0YRE8Arc7",
        "outputId": "a784c38d-353e-4e01-8661-3ecac4e203f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## read csv from local directory \n",
        "\n",
        "train_directory = '/content/MyDrive/MyDrive/Kaggles/kaggle_titanic/train.csv' \n",
        "test_directory = '/content/MyDrive/MyDrive/Kaggles/kaggle_titanic/test.csv'\n",
        "train_data = pd.read_csv(train_directory) \n",
        "test_data = pd.read_csv(test_directory)\n",
        "\n",
        "\n",
        "# Sex 랑 Embarked, Name\n",
        "\n",
        "train_data_frame =  pd.DataFrame(train_data,columns = ['Survived','Name','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']) \n",
        "test_data_frame = pd.DataFrame(test_data,columns =['Name','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked'])\n",
        "\n",
        "merged = (train_data_frame,test_data_frame )\n",
        "##개략적인 통계자료 보여주는 것\n",
        "#dataset.describe() \n",
        "\n",
        "# title 이라는 것으로 mr mrs 등 sex 관련하여 새로운 범주 데이터 생성 \n",
        "for dataset in merged :\n",
        "      dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "      dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
        " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "for dataset in merged : \n",
        "     dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "     dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "     dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "     dataset = dataset.drop(\"Name\",axis=1)\n",
        "\n",
        "#print(dataset)\n",
        "\n",
        "## 각 범주별 생존률을 따로 보여주는 것\n",
        "print(dataset[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
        "#print(dataset[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
        "#print( dataset[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean().sort_values(by='Survived',ascending=False))\n",
        "#print( dataset[['Title','Survived']].groupby(['Title'],as_index=False).mean().sort_values(by='Survived',ascending=False))\n",
        "\n",
        "# 범주형 데이터 숫자로 변환 \n",
        "\n",
        "for dataset in merged :\n",
        "      dataset['Sex'] = dataset['Sex'].map(({'male': 1 , 'female':0})).astype(int)\n",
        "      dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
        "      dataset['Title'] = dataset['Title'].map({'Mrs':5,'Miss':4,'Master':3,'Rare':2,'Mr':1}).astype(int)\n",
        "      dataset['Embarked'] = dataset['Embarked'].map(({'Q':3 ,'S':2 ,'C':1})).astype(int)\n",
        "\n",
        " \n",
        "## age nan 성별를 분류해서 바꾸기\n",
        "for dataset in merged :\n",
        "      dataset['Age'].fillna(dataset.groupby('Pclass')['Age'].transform('mean'), inplace=True)\n",
        "      dataset['Age'].fillna(dataset.groupby('Pclass')['Age'].transform('mean'), inplace=True)\n",
        "      dataset['Fare'].fillna(dataset.groupby('Pclass')['Fare'].transform('mean'),inplace=True)\n",
        "      \n",
        "\n",
        "## Embarked 범주형 데이터 더미데이터로 바꾸기\n",
        "#dataset = pd.get_dummies(dataset)\n",
        "#dataset = pd.get_dummies(dataset)\n",
        "\n",
        "train_data_frame['AgeBand'] = pd.qcut(train_data_frame['Age'], 5)\n",
        "print(train_data_frame[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True))\n",
        "##연속형 변수인 age 랑 Fare 를 범주형 변수로 바꿔주기\n",
        "for dataset in merged :  \n",
        "     dataset['FareBand'] = pd.qcut(dataset['Fare'], 6)\n",
        "     #print(dataset[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True))\n",
        "     \n",
        "     dataset.loc[(dataset['Fare']<=7.775),'Fare'] = 0\n",
        "     dataset.loc[(8.662>=dataset['Fare'])&(dataset['Fare']>7.775) ,'Fare']=1\n",
        "     dataset.loc[(8.662<dataset['Fare'])&(dataset['Fare']<14.454),'Fare']=2\n",
        "     dataset.loc[(14.454<=dataset['Fare'])&(dataset['Fare']<26.0),'Fare']=3\n",
        "     dataset.loc[(52.369>=dataset['Fare'])&(dataset['Fare']>=26.0),'Fare']=4\n",
        "     dataset.loc[(52.369<dataset['Fare']),'Fare']=5\n",
        "     \n",
        "     dataset['Fare']= dataset['Fare'].astype(int)\n",
        "\n",
        "     dataset.loc[(0.419<dataset['Age']) & (dataset['Age']<=20.0),'Age'] = 0\n",
        "     dataset.loc[(20.0<dataset['Age']) & (dataset['Age']<=25.141),'Age'] = 1\n",
        "     dataset.loc[(25.141<dataset['Age']) & (dataset['Age']<=30),'Age'] = 2\n",
        "     dataset.loc[(30.0<dataset['Age']) & (dataset['Age']<=38.233),'Age'] = 3\n",
        "     dataset.loc[(38.233<dataset['Age']) & (dataset['Age']<=80),'Age'] = 4\n",
        "     dataset['Age']= dataset['Age'].astype(int)\n",
        "\n",
        "\n",
        "print(test_data_frame.drop(['Name'],axis= 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z_WSIowBdI_",
        "outputId": "7e9f9329-92c2-411b-9b10-a94d8143be2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          AgeBand  Survived\n",
            "0   (0.419, 20.0]  0.458101\n",
            "1  (20.0, 25.141]  0.294574\n",
            "2  (25.141, 30.0]  0.386555\n",
            "3  (30.0, 38.233]  0.455696\n",
            "4  (38.233, 80.0]  0.372881\n",
            "     Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  Title           FareBand\n",
            "0         3    1    3      0      0     1         3      1     (7.762, 8.662]\n",
            "1         3    0    4      1      0     0         2      5    (-0.001, 7.762]\n",
            "2         2    1    4      0      0     2         3      1    (8.662, 14.454]\n",
            "3         3    1    2      0      0     2         2      1     (7.762, 8.662]\n",
            "4         3    0    1      1      1     2         2      5    (8.662, 14.454]\n",
            "..      ...  ...  ...    ...    ...   ...       ...    ...                ...\n",
            "413       3    1    1      0      0     1         2      1     (7.762, 8.662]\n",
            "414       1    0    4      0      0     5         1      2  (55.969, 512.329]\n",
            "415       3    1    4      0      0     0         2      1    (-0.001, 7.762]\n",
            "416       3    1    1      0      0     1         2      1     (7.762, 8.662]\n",
            "417       3    1    1      1      1     3         1      3     (14.454, 26.0]\n",
            "\n",
            "[418 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data_frame.drop(['Survived','Name','AgeBand','FareBand'],axis=1).to_numpy()\n",
        "Y_train = train_data_frame['Survived'].to_numpy()\n",
        "X_test = test_data_frame.drop(['Name','FareBand'],axis=1).to_numpy()\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "\n",
        "X_train = torch.from_numpy(X_train)\n",
        "Y_train = torch.from_numpy(Y_train)\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUBJzGVDSydc",
        "outputId": "5aafb177-75e9-484f-fc17-c3a0250fe18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 8)\n",
            "(891,)\n",
            "torch.Size([891, 8])\n",
            "torch.Size([891])\n",
            "(418, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 수요일에 끝내기\n",
        "import torch.nn as nn \n",
        "\n",
        "class MyModel(nn.Module) :\n",
        "    def __init__(self) :\n",
        "      super(MyModel, self).__init__()\n",
        "      self.fc1 = nn.Linear(8,1024)\n",
        "      self.relu1 = nn.ReLU() \n",
        "      self.fc2 = nn.Linear(1024,1024)\n",
        "      self.relu2 = nn.ReLU()\n",
        "      self.fc3 = nn.Linear(1024,2)\n",
        "      \n",
        "    \n",
        "    def forward(self, x) :\n",
        "       x = self.relu1(self.fc1(x))\n",
        "       x = self.relu2(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "     \n",
        "       return x \n",
        "  \n",
        "\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "L-dCltYs_Ff-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Batch가 필요한 데이터는 아니니.\n",
        "learning_rate = 0.1 \n",
        "model = MyModel() ; \n",
        "optimizer = torch.optim.SGD(params=model.parameters(),lr=learning_rate,momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.9) \n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iINtFn30_OPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training \n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch) :\n",
        "   loss.zero_grad() \n",
        "   y_pre  = model(X_train)\n",
        "   loss = loss(Y_train,y_pre)\n",
        "   print(\"loss :\"+loss)\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "   scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "mqPujkV8CJ5g",
        "outputId": "dd9413cc-6bcf-4a15-e605-66e222e09cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8c60c32e913b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m    \u001b[0my_pre\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m    \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss :\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-a34fad409a69>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Long"
          ]
        }
      ]
    }
  ]
}